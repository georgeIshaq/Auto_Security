"""
End-to-End Vulnerability Remediation Pipeline

This script orchestrates the entire DevSecOps workflow:
1.  (Assumes a vulnerability report already exists)
2.  Parses the vulnerability report.
3.  Uses the github-client to create GitHub issues for each finding.
4.  Clones the target repository.
5.  Initializes the ScoutAgent and TriageAgent.
6.  Loops through the findings and instructs the TriageAgent to fix them.
7.  The TriageAgent commits the fix to a new branch.
8.  Uses the github-client to create a pull request for the fix.
"""

import os
import shutil
import logging
import time
import subprocess
import argparse
import json
import sys
from git import Repo
from collections import defaultdict
from git.exc import GitCommandError

# Corrected local module imports to reflect the new package structure
from scout_agent.scout_agent import ScoutAgent
from scout_agent.triage_agent import TriageAgent
from scout_agent.shared_types import Finding
from vscanner.report_parser import ReportParser
# Use the new, advanced scanner class
from vscanner.vulnerability_scanner import VulnerabilityScanner
from github_client.github_integration import create_github_integration

# Configure logging to output to stderr
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', stream=sys.stderr)
logger = logging.getLogger(__name__)

# --- Configuration ---
GITHUB_TOKEN = os.getenv("GITHUB_TOKEN")
# The repository to clone and fix
# GITHUB_REPO_NAME = "tads-demo/repo_demo" # This will now be a command-line argument
LOCAL_REPO_PATH = "temp_vulnerable_repo"
REPORT_FILE = "vulnerability_report.text" # This will be the output path

def main(github_repo_name: str, output_file: str) -> dict:
    """Main function to run the remediation pipeline."""
    if not GITHUB_TOKEN:
        logger.error("GITHUB_TOKEN environment variable not set. Aborting.")
        return {"error": "GITHUB_TOKEN environment variable not set. Aborting."}

    # Initialize GitHub client and ScoutAgent
    try:
        gh = create_github_integration()
        logger.info(f"Successfully connected to GitHub as: {gh.user.login}")
        scout = ScoutAgent()
        logger.info("Scout Agent initialized.")
    except Exception as e:
        logger.error(f"Failed to initialize GitHub client: {e}")
        return {"error": f"Failed to initialize GitHub client: {e}"}

    # 1. Clone the repository
    logger.info(f"Cloning repository '{github_repo_name}' into '{LOCAL_REPO_PATH}'...")
    if os.path.exists(LOCAL_REPO_PATH):
        shutil.rmtree(LOCAL_REPO_PATH)
    repo = Repo.clone_from(f"https://{GITHUB_TOKEN}@github.com/{github_repo_name}.git", LOCAL_REPO_PATH)
    logger.info("Repository cloned successfully.")
    
    # Detect the default branch name (main or master)
    default_branch = repo.active_branch.name
    logger.info(f"Detected default branch: {default_branch}")

    # 2. Initialize the advanced scanner and run a scan
    logger.info(f"Initializing advanced scanner...")
    scanner = VulnerabilityScanner(scout_agent=scout)
    
    logger.info(f"Scanning the cloned repository at '{LOCAL_REPO_PATH}'...")
    scan_result = scanner.scan_directory(LOCAL_REPO_PATH)
    
    # 3. Generate and save the text report
    report_output_path = os.path.join(os.getcwd(), REPORT_FILE)
    logger.info(f"Generating vulnerability report at {report_output_path}...")
    report_content = scanner.generate_report(scan_result, 'text')
    with open(report_output_path, 'w', encoding='utf-8') as f:
        f.write(report_content)

    final_results = {
        "issues": [],
        "pull_requests": []
    }

    try:
        # 4. Parse the newly generated vulnerability report
        logger.info(f"Parsing vulnerability report: {report_output_path}")
        parser = ReportParser()
        findings = parser.parse(report_output_path)
        if not findings:
            logger.info("No findings in the report. Exiting.")
            return final_results

        # 3. Create GitHub issues for each finding
        logger.info("Creating GitHub issues for each finding...")
        for finding in findings:
            try:
                issue = gh.create_issue(
                    repo_name=github_repo_name,
                    title=f"Vulnerability: {finding.type} in {finding.file_path}",
                    body=f"**Severity:** {finding.severity}\n**File:** `{finding.file_path}` (Line: {finding.line_number})\n**Description:** {finding.message}\n**Evidence:**\n```\n{finding.evidence}\n```",
                    labels=["bug", "security", "autogenerated"]
                )
                finding.issue_number = issue.number
                logger.info(f"Created issue #{issue.number} for finding {finding.id}")
            except Exception as e:
                logger.error(f"Failed to create issue for finding {finding.id}: {e}")
        
        # Filter out findings for which we couldn't create an issue
        findings_with_issues = [f for f in findings if f.issue_number is not None]
        # Store a serializable version of the issues
        final_results["issues"] = [f.to_dict() for f in findings_with_issues]

        # Group findings by vulnerability type
        grouped_findings = defaultdict(list)
        for finding in findings_with_issues:
            grouped_findings[finding.type].append(finding)
        logger.info(f"Grouped findings into {len(grouped_findings)} topics.")

        # 5. Initialize Triage Agent and process topics
        triage = TriageAgent(scout_agent=scout, target_directory=LOCAL_REPO_PATH)

        # 6. Loop through each vulnerability topic and create a PR
        for vuln_type, findings_in_group in grouped_findings.items():
            logger.info(f"--- Processing topic: {vuln_type} ({len(findings_in_group)} findings) ---")
            branch_name = f"fix/{vuln_type.replace(' ', '_').lower()}"
            
            try:
                # Branching, fixing, pushing, and PR creation logic...
                logger.info(f"Creating branch '{branch_name}'...")
                
                # Clean up any existing local branch
                if branch_name in repo.heads:
                    repo.delete_head(branch_name, '-D')
                    logger.info(f"Deleted existing local branch '{branch_name}'")
                
                # Try to close any existing PR for this branch and delete the remote branch
                try:
                    # First, try to find and close any existing PR for this branch
                    try:
                        repo_obj = gh.get_repository(github_repo_name)
                        pulls = repo_obj.get_pulls(state='open', head=f"tads-demo:{branch_name}")
                        for pr in pulls:
                            pr.edit(state='closed')
                            logger.info(f"Closed existing PR #{pr.number} for branch '{branch_name}'")
                    except Exception as pr_error:
                        logger.debug(f"No existing PR to close for branch '{branch_name}': {pr_error}")
                    
                    # Then delete the remote branch
                    subprocess.run(
                        ["git", "push", "origin", "--delete", branch_name],
                        cwd=LOCAL_REPO_PATH,
                        capture_output=True,
                        text=True,
                        check=True
                    )
                    logger.info(f"Deleted existing remote branch '{branch_name}'")
                except subprocess.CalledProcessError:
                    # Remote branch doesn't exist, which is fine
                    logger.debug(f"Remote branch '{branch_name}' doesn't exist (this is normal)")
                
                # Create and checkout the new branch
                repo.create_head(branch_name).checkout()

                successful_commits = 0
                for finding in findings_in_group:
                    if triage.remediate_and_commit(finding):
                        successful_commits += 1
                
                # Only proceed if we have something to push
                if successful_commits > 0:
                    # --- Retry Logic for Push & PR Creation ---
                    MAX_RETRIES = 3
                    RETRY_DELAY_SECONDS = 5
                    for attempt in range(MAX_RETRIES):
                        try:
                            logger.info(f"Attempt {attempt + 1}/{MAX_RETRIES}: Pushing branch '{branch_name}' via subprocess...")
                            
                            # Use subprocess to get more detailed error output from command-line Git
                            # Using --force to overwrite the branch if it exists from a previous failed run
                            process = subprocess.run(
                                ["git", "push", "origin", branch_name, "--force"],
                                cwd=LOCAL_REPO_PATH,
                                capture_output=True,
                                text=True,
                                check=True  # Will raise CalledProcessError on non-zero exit code
                            )
                            logger.info(f"Branch '{branch_name}' pushed successfully.")

                            issue_numbers = [f"#{f.issue_number}" for f in findings_in_group if f.issue_number]
                            pr_body = f"This PR automatically remediates {successful_commits} vulnerabilities of type `{vuln_type}`.\n\nCloses: {', '.join(issue_numbers)}"
                            
                            pr = gh.create_pull_request(
                                repo_name=github_repo_name,
                                title=f"Fix: Remediate {vuln_type} vulnerabilities",
                                body=pr_body,
                                head=branch_name,
                                base=default_branch
                            )
                            logger.info(f"Successfully created Pull Request for topic '{vuln_type}': {pr.html_url}")
                            # Store a serializable version of the PR
                            final_results["pull_requests"].append({
                                "id": pr.id,
                                "title": pr.title,
                                "number": pr.number,
                                "status": pr.state,
                                "url": pr.html_url,
                                "created_at": pr.created_at.isoformat()
                            })
                            break # Success, exit retry loop
                        
                        except subprocess.CalledProcessError as e:
                            logger.warning(f"Git push command failed on attempt {attempt + 1}.")
                            logger.warning(f"Stderr: {e.stderr.strip()}")
                            if attempt < MAX_RETRIES - 1:
                                logger.info(f"Retrying in {RETRY_DELAY_SECONDS} seconds...")
                                time.sleep(RETRY_DELAY_SECONDS)
                            else:
                                logger.error(f"All {MAX_RETRIES} push attempts failed for topic '{vuln_type}'.")
                                raise e # Re-raise to be caught by the outer block
                        except Exception as e:
                            logger.warning(f"Attempt {attempt + 1} failed: {e}")
                            if attempt < MAX_RETRIES - 1:
                                logger.info(f"Retrying in {RETRY_DELAY_SECONDS} seconds...")
                                time.sleep(RETRY_DELAY_SECONDS)
                            else:
                                logger.error(f"All {MAX_RETRIES} attempts failed for topic '{vuln_type}'.")
                                raise
                else:
                    logger.warning(f"No successful commits for topic '{vuln_type}'. Skipping PR creation.")

            except Exception as e:
                logger.error(f"Failed to process topic '{vuln_type}': {e}")
            finally:
                # Return to default branch to prepare for the next topic
                repo.git.checkout(default_branch)
    
    finally:
        # 6. Clean up the local repository and report file
        if os.path.exists(LOCAL_REPO_PATH):
            shutil.rmtree(LOCAL_REPO_PATH)
            logger.info(f"Cleaned up local repository: {LOCAL_REPO_PATH}")
        if os.path.exists(report_output_path):
            os.remove(report_output_path)
            logger.info(f"Cleaned up report file: {report_output_path}")

    # Write the final results to the specified output file
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(final_results, f, indent=2)
        logger.info(f"Results saved to {output_file}")
    except IOError as e:
        logger.error(f"Failed to write results to {output_file}: {e}")

    return final_results

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Automated vulnerability remediation pipeline.")
    parser.add_argument(
        "repo",
        nargs="?",
        default="tads-demo/repo_demo",
        help="The GitHub repository to scan and fix (e.g., 'owner/repo'). Defaults to 'tads-demo/repo_demo'."
    )
    # Add an argument for the output file
    parser.add_argument(
        "--output-file",
        default="scan_results.json",
        help="The file to save the JSON results to."
    )
    args = parser.parse_args()
    
    main(args.repo, args.output_file)
